{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `etl_reduction` with *dask*\n",
    "The input is a txt file with long format.\n",
    "\n",
    "## Extract\n",
    "*dask* extracts the input in **parallel**\n",
    "\n",
    "## Reduction\n",
    "* select sequenced peptides\n",
    "* select certain patients (train, test) according to input\n",
    "* select peptides passing a certain threshold\n",
    "\n",
    "## Load\n",
    "* output the data as parquet files (in a separate folder)\n",
    "* or output the data as d.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import pyarrow as pa\n",
    "import dask.dataframe as dd\n",
    "import shutil\n",
    "\n",
    "from set_path import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class REDUCE:\n",
    "    def __init__(self,raw,pep,pat,output1,output2,\n",
    "                 freq_thres=0.5,fold_partition=5,bsize=\"100MB\"):\n",
    "        self.raw=raw\n",
    "        self.pep=pep\n",
    "        self.pat=pat\n",
    "        self.output1=output1\n",
    "        self.output2=output2\n",
    "        self.freq_thres=freq_thres\n",
    "        self.fold_partition=fold_partition\n",
    "        self.bsize=bsize\n",
    "        \n",
    "    def read_raw(self):\n",
    "        self.dfraw = dd.read_csv(self.raw,\n",
    "                 encoding='latin1',\n",
    "                  blocksize=self.bsize,\n",
    "                usecols=['Muster', 'Name', 'ProbenID', 'Amplitude'])\n",
    "    def select_pep(self):\n",
    "        \"\"\"select peptides (sequenced) from raw\"\"\"\n",
    "        if self.pep:\n",
    "            dfseq=pd.read_excel(self.pep,index_col=0)\n",
    "\n",
    "            # select sequenced peptide from ml1 \n",
    "            pepseq=dfseq[dfseq['Sequence'].notnull()].index.tolist()\n",
    "            pepseq=np.sort([int('999'+i[1:]) for i in pepseq])\n",
    "            \n",
    "            # filter only seq. peptides from raw\n",
    "            self.dfraw=self.dfraw[self.dfraw.Muster.isin(pepseq)]\n",
    "            \n",
    "    def select_pat(self):\n",
    "        \"\"\"select patients (training or test) from raw\"\"\"\n",
    "        if self.pat:\n",
    "            # if we need to select patients\n",
    "            dftrain=pd.read_csv(self.pat,index_col=0)\n",
    "            # define number of patients selected\n",
    "            self.npatients=len(dftrain)\n",
    "#             print (dftrain.columns.tolist())\n",
    "#             print (dftrain.head())\n",
    "            pattrain=np.sort(dftrain.index.tolist())\n",
    "            # select patietns\n",
    "            self.dfraw=self.dfraw[self.dfraw.ProbenID.isin(pattrain)]\n",
    "            print ('self.npatients', self.npatients)\n",
    "            print ('self.dfraw.shape',len(self.dfraw))\n",
    "        \n",
    "    def pep_freq(self):\n",
    "        \"\"\"select peptides which present in  >freq_thes of patients\n",
    "        freq_thres default=0.5\"\"\"\n",
    "        freq_thres=self.freq_thres*self.npatients\n",
    "        \n",
    "        # calculate frequency of each peptide\n",
    "        # it is important to have groupby dataframe as pandas df by compute()\n",
    "        a=self.dfraw.groupby('Muster')['ProbenID'].size().compute()\n",
    "        \n",
    "        # bind the frequency to raw data\n",
    "        mask=self.dfraw['Muster'].map(a)\n",
    "        \n",
    "        # select frequency larger than freq_thres by masking\n",
    "        self.dfraw=self.dfraw[mask>=freq_thres]\n",
    "        \n",
    "    def repartition(self):\n",
    "        \"\"\"repartition dask dataframe into smaller number of chunks\n",
    "        number of chunks is reduced by 1/n, default n=5\n",
    "        so that we still have around 100MB of data in each chunk\n",
    "        \"\"\"\n",
    "        self.dfraw = self.dfraw.repartition(npartitions=self.dfraw.npartitions // self.fold_partition)\n",
    "    \n",
    "    def export_parquet(self):\n",
    "        \n",
    "        # create pyarrow schema for data type\n",
    "        padict=pa.schema([(\"Muster\",pa.int64()),\\\n",
    "                                    (\"Name\",pa.int64()),\\\n",
    "                                    (\"ProbenID\",pa.string()),\\\n",
    "                                   ('Amplitude',pa.float64()),\\\n",
    "                                   #('fidAuswertung',pa.int64()),\\\n",
    "                                   # ('Dateiname',pa.string())\\\n",
    "                         ])\n",
    "        \n",
    "        # if destination exists, empty it before creating new\n",
    "        if os.path.exists(self.output1):\n",
    "                shutil.rmtree(self.output1)\n",
    "        os.makedirs(self.output1)\n",
    "        # export to parquet files\n",
    "        self.dfraw.to_parquet(self.output1,\\\n",
    "                            engine='pyarrow',\\\n",
    "                            schema=padict,\\\n",
    "                           append=False)\n",
    "    def export_csv(self):\n",
    "        self.dfraw.compute().to_csv(self.output2,index=None)\n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.npatients 7939\n",
      "self.dfraw.shape 5693027\n"
     ]
    }
   ],
   "source": [
    "# extract\n",
    "x1=REDUCE(raw=f1+'qryMusterExportMFinderMF.txt',\\\n",
    "          pep=f1+'ML1 02122020 semi-final.xlsx',\\\n",
    "          pat=f2+'Tianlin_GFR_CKD_EPI_cleaned_20201005.csv',\\\n",
    "          output1=f2+'reduced_all/',\\\n",
    "          output2=None,\\\n",
    "         bsize=\"100MB\")\n",
    "x1.read_raw()\n",
    "# reduce\n",
    "x1.select_pep()\n",
    "x1.select_pat()\n",
    "x1.pep_freq()\n",
    "# load\n",
    "x1.repartition()\n",
    "x1.export_parquet()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}