{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data in steps\n",
    "* The original data \"Tianlin_GFR_CKD_EPI_31082020.xls\" resides in `project_calc/data/original`.\n",
    "<br>It contains 14345 rows and 85 columns.\n",
    "* The disease group \"disease_group_SamHobson_PS_SH.xlsx\" resides in `project_calc/data/original`.\n",
    "* The NTCVD info from GB \"Tianlin_ntcvd_all_checkbyGB.xlsx\" and \"checkedByGB_Tianlin_ntcvd.xlsx\" reside in `project_calc/data/original`.\n",
    "\n",
    "## python-class CLEAN1\n",
    "1. `x1=CLEAN1(f1+'Tianlin_GFR_CKD_EPI_31082020.xls')` load the data \n",
    "    * $\\Rightarrow$ Running `x1=CLEAN1(f1+'Tianlin_GFR_CKD_EPI_31082020.xls')` displays 'It contains 14345 rows and 85 columns'\n",
    "    * uncomment to see column names\n",
    "    * uncomment to see study names\n",
    "    \n",
    "1. `remove_nan` to remove one patient with nan value in eGFR\n",
    "    * $\\Rightarrow$ Running `x1.remove_nan()` displays: 'It contains 14344 rows and 85 columns'</tab>    \n",
    "   \n",
    "2. `remove_study` to remove studies with 'fidStudie' in `['FROG_ICU','CIHF','PCHF','MTWA','Haubitz_geblindet_II','Stroke']`\n",
    "    * $\\Rightarrow$ Running `x1.remove_study()` displays 'It contains 10650 rows and 85 columns'</tab>\n",
    "    * 'FROG_ICT' consists of ICU patients which have atypical peptidomics\n",
    "    * 'CIHF', 'PCHF','MTWA': Harald suggested me removing them\n",
    "    * 'Haubitz_geblindet_II': it is a blinded study with unknown patients' data\n",
    "    * 'Stroke': with incredible eGFR\n",
    "3. `remove_s_creatinine_bySam` to remove 4 patients\n",
    "    * Sam pointed out they had rocket high serum creatinine values (email on 20200911)\n",
    "4. `remove_dialysis` to remove patients underwent dialysis\n",
    "    * input1=`'checkedByGB_Tianlin_ntcvd.xlsx'` provided by GB\n",
    "    * those are **NTCVD** patients only\n",
    "3. `remove_age_below18` to remove patients age below 18\n",
    "    * because they have healthier peptidomics albeit low eGFR\n",
    "4. `remove_egfr_above` to remove patients with eGFR above an arbitrary number n\n",
    "    * $\\Rightarrow$ Running `x1.remove_egfr_above(150)` displays 'It contains 8128 rows and 85 columns'\n",
    "4. `gfr_predictionHBI` to correct eGFR values for patients in studie 'Predictions_HBI'.It is known that some patients bear the wrong serum creatinine unit. For patiens with extra smaller serum creatinine (<0.1), I:\n",
    "    1. multiply serum creatinine with 88.42 to convert mmol/L to mg/dL\n",
    "    2. apply the EPI formula to calculate eGFR for male and female (we assume all are non-black)\n",
    "    3. compare the eGFR with the website [calculate-by-Qxmd](https://qxmd.com/calculate/calculator_251/egfr-using-ckd-epi)\n",
    "    4. $\\Rightarrow$ Running `x1.gfr_predictionHBI()` displays no output (because it does not remove/add rows, but you can uncomment the `print` line to see the corrected eGFR and serum creatinine\n",
    "5. `merge_diseases` to merge subdiseases into bigger group\n",
    "    * input= `f1+'disease_group_SamHobson_PS_SH.xlsx'\n",
    "    * it first merge subgroups into a bigger groups\n",
    "    * then it removes the subgroups that have been merged\n",
    "    * $\\Rightarrow$ Running `x1.merge_diseases()` displays 'It contains 8128 rows and 18 columns'\n",
    "6. `exclude_diseases` to exclude patients with value \"1.0\" in the \"Exclude\" column\n",
    "    * $\\Rightarrow$ Running `x1.exclude_diseases()` displays 'It contains 7953 rows and 17 columns'\n",
    "7. `update_Calcification` to update diseases according to data given by Sam\n",
    "    * update CVD and diabetes\n",
    "    * all patients from \"Calcification\" were assigned \"1\" for CKD\n",
    "7. `insert_col_from_sql` insert columns from files queried based on my own sql script `project_calc/sql/calc_20200915.txt`\n",
    "    ```\n",
    "    #urinary creatinine\n",
    "    SELECT    o.Probe_id, pa.Parameter, pa.Einheit, p.Datum, p.Wert\n",
    "    FROM         dbo.tblP_Parameter p INNER JOIN\n",
    "                          dbo.tblOriginalproben o ON p.fidPatient = o.fidPatient INNER JOIN\n",
    "                          dbo.tblParameter pa ON p.fidParameter = pa.idParameter\n",
    "    WHERE     (p.fidParameter IN (9,47,157))\n",
    "\n",
    "    #ACR\n",
    "    SELECT    o.Probe_id, pa.Parameter, pa.Einheit, p.Datum, p.Wert\n",
    "    FROM         dbo.tblP_Parameter p INNER JOIN\n",
    "                          dbo.tblOriginalproben o ON p.fidPatient = o.fidPatient INNER JOIN\n",
    "                          dbo.tblParameter pa ON p.fidParameter = pa.idParameter\n",
    "    WHERE     (p.fidParameter=56)\n",
    "    ```\n",
    "    * `x1.insert_col_from_sql(f1+'u_creatinine_unit_date.xls','U_Kreatinin')` inserts urinary creatinine and its units (notice that it carries two units, \"mg/dL\" and \"mmol/l\").\n",
    "    * `x1.insert_col_from_sql(f1+'acr_unit_date.xls','acr')` inserts urinary albumin to creatinine ratio. It carries one unit, \"mg/g\"\n",
    "    \n",
    "7. `update_NTCVD` to update **NTCVD** patients according to data given by GB\n",
    "    * input1=`'Tianlin_ntcvd_all_checkbyGB.xlsx'`\n",
    "    * it updates columns \"U_Albumin\" and \"acr\"\n",
    "    * it displays the number of non-nan rows of \"U_Albumin\" and \"acr\" before and after update\n",
    "    * uncomment to print \"U_Albumin\" and \"acr\" of NTCVD patients\n",
    "7. `replace_0_by_nan` to replace 0 by nan for any arbitrary column\n",
    "    * we replace 0 in `U_Albumin`\n",
    "8. `replace_0_by_min` to replace 0 by the smallest non-zero value in the same study\n",
    "    * we replace 0 in `U_Albumin` by running `x1.replace_0_by_min('U_Albumin')`, you can theoretically do it with any column name\n",
    "    * It is a group-wise operation: e.g., \n",
    "        * 0 in study='CVD' will be replaced by 0.5, which is the smallest record in 'CVD', \n",
    "        * while 0 in study='FSGF' will be replaced by 1.8, which is the smallest record in 'FSGF'\n",
    "7. `assign_sex` to convert \"gender\" to boolean values\n",
    "    * \"männlich\" to 1\n",
    "    * \"weblich\" to 0\n",
    "    * $\\Rightarrow$ Running `x1.assign_sex()` displays no output \n",
    "8. `albuminuria_group` to assign normal/micro/macro albuminuria, cut at 30 and 300 mg/g\n",
    "    * create three columns `['normalalbuminuria', 'microalbuminuria', 'macroalbuminuria']` with boolean values\n",
    "9. `egfr_group` to assign eGFR group according to Sam, cut at arbitrary thresholds\n",
    "    * create one columns `egfr_group` with group labels \n",
    "    * larger the eGFR, smaller the group label\n",
    "6. `export_excel` to export the cleaned table to an .xlsx file.\n",
    "    * $\\Rightarrow$ Running `x1.export_excel(path/name)` displays the path and name of the cleaned file.\n",
    "\n",
    "    \n",
    "### Remarks: eGFR is given by the formula\n",
    "$GFR = 141 * \\min(Scr/κ,1)^{\\alpha}* \\max(Scr/κ, 1)^{-1.209} * 0.993^{Age} * 1.018 [if female] * 1.159 [if black]$\n",
    "* Scr is serum creatinine (mg/dL), \n",
    "* κ is 0.7 for females and 0.9 for males, \n",
    "* α is -0.329 for females and -0.411 for males, \n",
    "* min indicates the minimum of Scr/κ or 1, and max indicates the maximum of Scr/κ or 1.\n",
    "\n",
    "### To note: \n",
    "f1 and f2 are location+file name of original (input) and cleaned (output) data respectively. They were named according to my own folder setting. (I stored the original and cleaned file at two places so that I do not mix them up). \n",
    "<br>It is completely optional to use the same folder setting as mine, but in case you want, below is my setting:\n",
    "* I created a main folder called \"project_calc\"\n",
    "    * \"project_calc\" has two subfolders, called \"python\" and \"data\" respectively\n",
    "    * \"data\" has two subfolders, called \"curated\" and \"original respectively\n",
    "* The script, \"PATIENT-1-clean_data.ipynb\" is stored in folder \"project_calc/python\"\n",
    "* The original data 'Tianlin_GFR_CKD_EPI_31082020.xls' is folder \"project_calc/data/original\"\n",
    "* The cleaned data (output) will be  stored in \"project_calc/data/curated/\" once it is generated from the script.\n",
    "\n",
    "In case you adopt the same folder setting, you do not have to change anything from the script, just run it!\n",
    "\n",
    "<br> Alternatively, if you have the input data and this script in the SAME folder, you do not need to specify f1 and f2,because current path=default path. So: just change the two lines:\n",
    "* x1=CLEAN1(f1+'Tianlin_GFR_CKD_EPI_31082020.xls') to x1=CLEAN1('Tianlin_GFR_CKD_EPI_31082020.xls')\n",
    "* x1.export_excel(f2+'what-ever-name-you-like.xlsx') to x1.export_excel('what-ever-name-you-like.xlsx')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from set_path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gfr_female(x): #calculate eGFR-EPI for female\n",
    "    kappa=0.7\n",
    "    alpha=-0.329\n",
    "    return 141*np.power(min(x['S_Kreatinin']/kappa,1),alpha)*np.power(max(x['S_Kreatinin']/kappa,1),-1.209)\\\n",
    "                    *np.power(0.993,x['Age'])*1.018\n",
    "\n",
    "def gfr_male(x): #calculate eGFR-EPI for male\n",
    "    kappa=0.9\n",
    "    alpha=-0.411\n",
    "    return 141*np.power(min(x['S_Kreatinin']/kappa,1),alpha)*np.power(max(x['S_Kreatinin']/kappa,1),-1.209)\\\n",
    "                    *np.power(0.993,x['Age'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLEAN1:\n",
    "    def __init__(self,input1):\n",
    "        self.df1=pd.read_excel(input1,index_col=1)\n",
    "        # display original no. of rows and columns of the table\n",
    "        print ('It contains',self.df1.shape[0],'rows and', self.df1.shape[1],'columns')\n",
    "        # display column names\n",
    "#         print (self.df1.columns.tolist())\n",
    "#         print (self.df1.head)\n",
    "        # display study names in column 'fidStudie'\n",
    "#         print (self.df1.fidStudie.unique())\n",
    "#         print (self.df1.gender.unique())\n",
    "    def remove_nan(self): # remove one patient without eGFR information\n",
    "\n",
    "        self.df1=self.df1[self.df1.GFR_CKD_EPI.notnull()]\n",
    "        print ('It contains',self.df1.shape[0],'rows and', self.df1.shape[1],'columns')\n",
    "        \n",
    "    def remove_study(self): # remove unwanted studies \n",
    "        \n",
    "        # name of the unwanted studies \n",
    "        studies=['FROG_ICU','CIHF','PCHF','MTWA','Haubitz_geblindet_II','Stroke'] \n",
    "        self.df1=self.df1[~self.df1.fidStudie.isin(studies)]\n",
    "        print ('It contains',self.df1.shape[0],'rows and', self.df1.shape[1],'columns')\n",
    "        \n",
    "    def remove_s_creatinine_bySam(self):\n",
    "        \n",
    "        slist=['1971-Comper_Diabetes-Urin-4625',\n",
    "                '591-FSGS-Urin-2037',\n",
    "                '5-FSGS-Urin-130',\n",
    "                '5-FSGS-Urin-692']\n",
    "        \n",
    "        self.df1=self.df1[~self.df1.index.isin(slist)]\n",
    "        print ('It contains',self.df1.shape[0],'rows and', self.df1.shape[1],'columns')\n",
    "        \n",
    "    def remove_dialysis(self,input1): # remove NTCVD patients with dialysis='Y'\n",
    "        \n",
    "        df1=pd.read_excel(input1) #input from Guilia\n",
    "        \n",
    "        dialysis=df1.loc[df1['Dialysis Y/N']=='Y','SampleID'].tolist() #list ID of patients with dialysis=I\n",
    "        \n",
    "        self.df1=self.df1[~self.df1.index.isin(dialysis)] # exclude those in the above list\n",
    "        \n",
    "        print ('It contains',self.df1.shape[0],'rows and', self.df1.shape[1],'columns')\n",
    "    \n",
    "    def remove_age_below18(self): # remove patient below 18\n",
    "        \n",
    "        self.df1=self.df1[self.df1.Age>=18] # select age>=18\n",
    "        \n",
    "        print ('It contains',self.df1.shape[0],'rows and', self.df1.shape[1],'columns')\n",
    "    \n",
    "    def remove_egfr_above(self,n): # remove patients with eGFR > n\n",
    "        \n",
    "        self.df1=self.df1[self.df1.GFR_CKD_EPI<=n] # select eGFR <=n\n",
    "        \n",
    "        print ('It contains',self.df1.shape[0],'rows and', self.df1.shape[1],'columns')\n",
    "        \n",
    "    def egfr_predictionHBI(self): # correct eGFR of predictions_HBI patients\n",
    "        \n",
    "        # mask1 identifies the predictions_HIB patients with extra small s_creatinine\n",
    "        mask1=(self.df1.fidStudie=='Predictions_HIB')&(self.df1.S_Kreatinin<0.1)\n",
    "        \n",
    "        # convert s_creatinine for mask1 patients from mmol/L to mg/dL\n",
    "        self.df1.loc[mask1,'S_Kreatinin']*=88.42\n",
    "#         print (self.df1.loc[mask1,['fidStudie','OrigID', 'S_Kreatinin']])\n",
    "\n",
    "        # calculate egfr-EPI of predictionHBI patients with sexfemale\n",
    "        mask_f=(self.df1.fidStudie=='Predictions_HIB')&(self.df1.gender=='weiblich')\n",
    "        self.df1.loc[mask_f,'GFR_CKD_EPI']=self.df1.loc[mask_f].apply(gfr_female,axis=1)\n",
    "#         print (self.df1.loc[mask_f,['Age','gender', 'S_Kreatinin','GFR_CKD_EPI']])\n",
    "\n",
    "        # calculate egfr-EPI of predictionHBI with sex male\n",
    "        mask_m=(self.df1.fidStudie=='Predictions_HIB')&(self.df1.gender=='männlich')\n",
    "        self.df1.loc[mask_m,'GFR_CKD_EPI']=self.df1.loc[mask_m].apply(gfr_male,axis=1)\n",
    "#         print (self.df1.loc[mask_m,['Age','gender', 'S_Kreatinin','GFR_CKD_EPI']])\n",
    "        \n",
    "    def merge_diseases(self,input2):# merge diseases into groups\n",
    "        \n",
    "        # load group_disease from Sam but omit the last row \"Gesamtergebnis\"\n",
    "        df2=pd.read_excel(input2,index_col=0).iloc[:-1,:]\n",
    "#         print (df2.columns.tolist())\n",
    "\n",
    "        \"\"\"create a dictionary with six groups according to Sam\n",
    "                        group name = column name\n",
    "        ['Exclude','Control', 'Diabetes/Obesity/metabolic syndrome', \n",
    "        'Chronic kidney disease', 'CVD/Hypertension', 'Other diseases', \n",
    "        'More Information Needed']\n",
    "        \"\"\" \n",
    "        disease_dict=df2.to_dict()\n",
    "#         print (disease_dict)\n",
    "\n",
    "        # remove two groups we do not need\n",
    "        del disease_dict['More Information Needed']\n",
    "        del disease_dict['Control']\n",
    "        \n",
    "        \"\"\"merge diseases into five groups: \n",
    "        ['Exclude','Diabetes/Obesity/metabolic syndrome', \n",
    "        'Chronic kidney disease', 'CVD/Hypertension', 'Other diseases']\n",
    "        \"\"\" \n",
    "        for i in disease_dict:\n",
    "            self.df1[i]=np.where(self.df1[[k for k,v in disease_dict[i].items() if v==1.0]].any(axis=1),\n",
    "                                 1,np.nan)\n",
    "            \n",
    "        # remove subdiseases columns\n",
    "        self.df1.drop(list(df2.index),axis=1,inplace=True)\n",
    "        self.df1.drop('Gesamtergebnis',axis=1,inplace=True)\n",
    "        \n",
    "        print ('It contains',self.df1.shape[0],'rows and', self.df1.shape[1],'columns')\n",
    "        \n",
    "    def exclude_diseases(self): #exclude patients with 1.0 in \"exclude\" columns\n",
    "        \n",
    "        self.df1=self.df1[self.df1['Exclude'].isnull()]\n",
    "        self.df1.drop('Exclude',axis=1,inplace=True) # delete the \"exclude\" columns\n",
    "        \n",
    "        print ('It contains',self.df1.shape[0],'rows and', self.df1.shape[1],'columns')\n",
    "    def update_Calcification(self,input1):\n",
    "        print ('Before updating Calcification:')\n",
    "        print ('There are',self.df1['Diabetes/Obesity/metabolic syndrome'].count(), 'non-null rows of diabetes')\n",
    "        print ('There are',self.df1['CVD/Hypertension'].count(), 'non-null rows of CVD')\n",
    "        print ('There are',self.df1['Chronic kidney disease'].count(), 'non-null rows of CKD')\n",
    "        \n",
    "    \n",
    "        # read Calcification data from Sam, notice column 'NTCVD-ID' must be converted to str for merge to work\n",
    "        df2=pd.read_excel(input1,dtype={'DNAtx Patient Number':str})\n",
    "    \n",
    "                                                              \n",
    "        df2.rename({'Diabetes_no0_yes1':'Diabetes/Obesity/metabolic syndrome',\n",
    "                   'CVD_No0_Yes1':'CVD/Hypertension'},axis=1,inplace=True)\n",
    "        \n",
    "    \n",
    "        # create a temporary df3 that:\n",
    "        # its index is 'SampleID'\n",
    "        # it merges GB file with original data based on 'NTCVD-ID'\n",
    "        df3=pd.DataFrame(self.df1.iloc[:,0]).reset_index()\\\n",
    "                        .merge(df2,left_on='OrigID',right_on='DNAtx Patient Number')\\\n",
    "                        .set_index('SampleID')\n",
    "\n",
    "        # update original data based on temporary df3\n",
    "        self.df1.update(df3)\n",
    "        \n",
    "        # set all as having CVD\n",
    "        self.df1.loc[self.df1['fidStudie']=='Calcification','Chronic kidney disease']=1\n",
    "        print ('After updating Calcification:')\n",
    "        print ('There are',self.df1['Diabetes/Obesity/metabolic syndrome'].count(), 'non-null rows of diabetes')\n",
    "        print ('There are',self.df1['CVD/Hypertension'].count(), 'non-null rows of CVD')\n",
    "        print ('There are',self.df1['Chronic kidney disease'].count(), 'non-null rows of CKD')\n",
    "\n",
    "        \n",
    "    def insert_col_from_sql(self,input1,colname): # insert colname from sql-generated xls by merging index\n",
    "        \n",
    "        uc=pd.read_excel(input1,index_col=0)\n",
    "#         print ('shape of input1',uc.shape)\n",
    "#         print (uc.columns.tolist())\n",
    "        \n",
    "        # keep the UNIQUE index with earliest date as possible\n",
    "        uc.sort_values(['Datum','Einheit'],inplace=True)\n",
    "        uc = uc[~uc.index.duplicated(keep='first')]\n",
    "        \n",
    "        uc.drop(['Parameter', 'Datum'],inplace=True,axis=1)\n",
    "        \n",
    "        uc.rename({'Wert':colname,\n",
    "                      'Einheit':'unit_'+colname},axis=1, inplace=True)\n",
    "        \n",
    "        # merge input1 with original data based on index\n",
    "        self.df1=self.df1.join(uc,how='left')\n",
    "        \n",
    "        print ('It contains',self.df1.shape[0],'rows and', self.df1.shape[1],'columns')\n",
    "        \n",
    "        print ('Summary:')\n",
    "        print ('Type of units',self.df1['unit_'+colname].unique().tolist())\n",
    "        print ('There are',self.df1[colname].count(), 'non-null rows of',colname)\n",
    "        self.df1.drop('unit_'+colname,axis=1,inplace=True)\n",
    "\n",
    "        \n",
    "    def update_NTCVD(self,input1): #update NTCVD patients act. data provided by GB\n",
    "        \n",
    "        print ('Before updating NTCVD:')\n",
    "        print ('There are',self.df1['U_Albumin'].count(), 'non-null rows of U_Albumin')\n",
    "        print ('There are',self.df1['acr'].count(), 'non-null rows of acr')\n",
    "    \n",
    "        # read NTCVD data from GB, notice column 'NTCVD-ID' must be converted to str for merge to work\n",
    "        df2=pd.read_excel(input1,sheet_name=1,dtype={'NTCVD-ID':str})\n",
    "\n",
    "        # for the columns to be updated, rename them in GB file so that they are the same as original data\n",
    "        df2.rename({'UrinAlbumin (UK) mg/dl':'U_Albumin',\n",
    "                   'UrinAlbumin mg/gKrea (UK)':'acr'},axis=1, inplace=True)\n",
    "        \n",
    "#         print (df2.shape)\n",
    "#         print (df2.columns.tolist())\n",
    "#         print (df2.head())\n",
    "\n",
    "        # create a temporary df3 that:\n",
    "        # its index is 'SampleID'\n",
    "        # it merges GB file with original data based on 'NTCVD-ID'\n",
    "        df3=pd.DataFrame(self.df1.iloc[:,0]).reset_index()\\\n",
    "                        .merge(df2,left_on='OrigID',right_on='NTCVD-ID')\\\n",
    "                        .set_index('SampleID')\n",
    "\n",
    "        # update original data based on temporary df3\n",
    "        self.df1.update(df3)\n",
    "        \n",
    "        print ('After updating NTCVD:')\n",
    "        print ('There are',self.df1['U_Albumin'].count(), 'non-null rows of U_Albumin')\n",
    "        print ('There are',self.df1['acr'].count(), 'non-null rows of acr')\n",
    "\n",
    "        # uncomment to print the updated columns \n",
    "    #     print (df1.loc[df1.fidStudie=='NTCVD',['U_Albumin','acr']])\n",
    "    \n",
    "    def replace_0_by_nan(self,colname): # replace 0 by nan in any designated column\n",
    "        \n",
    "        print ('number of nan before replacement:',self.df1[colname].isnull().sum())\n",
    "        print ('number of 0 before replacement:',(self.df1[colname]==0).sum())\n",
    "        \n",
    "        self.df1[colname]=self.df1[colname].replace(0,np.nan)\n",
    "        \n",
    "        print ('number of nan after replacement:',self.df1[colname].isnull().sum())\n",
    "        print ('number of 0 after replacement:',(self.df1[colname]==0).sum())\n",
    "        \n",
    "    def replace_0_by_min(self,colname): # replace 0 by smallest non-zero value in a groupwise manner\n",
    "        \n",
    "        print ('number of nan before replacement:',self.df1[colname].isnull().sum())\n",
    "        print ('number of 0 before replacement:',(self.df1[colname]==0).sum())\n",
    "        \n",
    "        # covert nan to inf, then 0 to nan\n",
    "        self.df1[colname] = self.df1[colname].replace(np.nan,np.inf).replace(0,np.nan)\n",
    "        \n",
    "        # fill nan with smallest value in group 'fidStudie'\n",
    "        self.df1[colname]=self.df1[colname].fillna(self.df1.groupby('fidStudie')[colname].transform('min'))\n",
    "        \n",
    "        # convert inf bach to nan, so that we preserve all inf records\n",
    "        self.df1[colname]=self.df1[colname].replace(np.inf,np.nan)\n",
    "        \n",
    "        print ('number of nan after replacement:',self.df1[colname].isnull().sum())\n",
    "        print ('number of 0 after replacement:',(self.df1[colname]==0).sum())\n",
    "        \n",
    "    def assign_sex(self): #assign boolean to sex, m=0, f=1\n",
    "        \n",
    "        self.df1['gender']=np.where(self.df1['gender']=='männlich',1,0)\n",
    "        \n",
    "    def albuminuria_group(self):\n",
    "        self.df1['normalalbuminuria']=np.where(self.df1['acr']<30,1,0)-self.df1['acr']+self.df1['acr']\n",
    "        self.df1['microalbuminuria']=np.where(((self.df1['acr']<300)&(self.df1['acr']>=30)),1,0)-self.df1['acr']+self.df1['acr']\n",
    "        self.df1['macroalbuminuria']=np.where(self.df1['acr']>=300,1,0)-self.df1['acr']+self.df1['acr']\n",
    "        \n",
    "        print ('number of 1 in normalalbuminuria:',(self.df1['normalalbuminuria']==1).sum())\n",
    "        print ('number of 0 in normalalbuminuria:',(self.df1['normalalbuminuria']==0).sum())\n",
    "        print ('number of 1 in microalalbuminuria:',(self.df1['microalbuminuria']==1).sum())\n",
    "        print ('number of 0 in microalalbuminuria:',(self.df1['microalbuminuria']==0).sum())\n",
    "        print ('number of 1 in macroalalbuminuria:',(self.df1['macroalbuminuria']==1).sum())\n",
    "        print ('number of 0 in macroalalbuminuria:',(self.df1['macroalbuminuria']==0).sum())\n",
    "        \n",
    "    def egfr_group(self,thres,labels):\n",
    "        \n",
    "        thres=[0]+thres+[np.inf]\n",
    "        \n",
    "        self.df1['egfr_group']=self.df1[['GFR_CKD_EPI']].apply(lambda x : pd.cut(x,thres,labels=labels))\n",
    "        print (self.df1.groupby('egfr_group')['GFR_CKD_EPI'].describe())\n",
    "                                                        \n",
    "    \n",
    "    def export_excel(self,output1):\n",
    "        print ('The cleaned table can be found at',output1)\n",
    "        self.df1.to_excel(output1)\n",
    "    def export_csv(self,output1):\n",
    "        print ('The cleaned table can be found at',output1)\n",
    "        self.df1.to_csv(output1)\n",
    "    def export_csv_train_test(self,output1,output2):\n",
    "        maskc=self.df1['fidStudie']=='Calcification'\n",
    "        \n",
    "        # training dataset do not have \"Calcification\"\n",
    "        train=self.df1[~maskc]\n",
    "        train.to_csv(output1)\n",
    "        print ('The cleaned train data can be found at',output1)\n",
    "        print ('number of rows in train:',len(train))\n",
    "        \n",
    "        # test dataset contains only \"Calcification\"\n",
    "        test=self.df1[maskc]\n",
    "        test.to_csv(output2)\n",
    "        print ('The cleaned test data can be found at',output2)\n",
    "        print ('number of rows in test:',len(test))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It contains 14345 rows and 84 columns\n",
      "It contains 14344 rows and 84 columns\n",
      "It contains 14340 rows and 84 columns\n",
      "It contains 10646 rows and 84 columns\n",
      "It contains 10636 rows and 84 columns\n",
      "It contains 8387 rows and 84 columns\n",
      "It contains 8114 rows and 84 columns\n",
      "It contains 8114 rows and 17 columns\n",
      "It contains 7939 rows and 16 columns\n",
      "Before updating Calcification:\n",
      "There are 3305 non-null rows of diabetes\n",
      "There are 1697 non-null rows of CVD\n",
      "There are 1373 non-null rows of CKD\n",
      "After updating Calcification:\n",
      "There are 3372 non-null rows of diabetes\n",
      "There are 1758 non-null rows of CVD\n",
      "There are 1413 non-null rows of CKD\n",
      "WARNING *** file size (15736254) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "It contains 7939 rows and 18 columns\n",
      "Summary:\n",
      "Type of units [nan, 'mg/g']\n",
      "There are 1545 non-null rows of acr\n",
      "Before updating NTCVD:\n",
      "There are 3943 non-null rows of U_Albumin\n",
      "There are 1545 non-null rows of acr\n",
      "After updating NTCVD:\n",
      "There are 4051 non-null rows of U_Albumin\n",
      "There are 1551 non-null rows of acr\n",
      "number of nan before replacement: 3888\n",
      "number of 0 before replacement: 88\n",
      "number of nan after replacement: 3888\n",
      "number of 0 after replacement: 0\n",
      "number of 1 in normalalbuminuria: 634\n",
      "number of 0 in normalalbuminuria: 917\n",
      "number of 1 in microalalbuminuria: 659\n",
      "number of 0 in microalalbuminuria: 892\n",
      "number of 1 in macroalalbuminuria: 258\n",
      "number of 0 in macroalalbuminuria: 1293\n",
      "             count        mean        std       min        25%        50%  \\\n",
      "egfr_group                                                                  \n",
      "0           3335.0  108.308254  13.114878  90.00433  97.379485  105.54280   \n",
      "1           2794.0   76.534328   8.318309  60.06956  70.348637   76.79747   \n",
      "2           1317.0   46.602883   9.067687  30.07345  38.368580   47.76141   \n",
      "3            493.0   21.350435   6.888654   3.70000  17.370600   23.13000   \n",
      "\n",
      "                  75%    max  \n",
      "egfr_group                    \n",
      "0           117.37360  150.0  \n",
      "1            83.74727   90.0  \n",
      "2            54.98604   60.0  \n",
      "3            26.94793   30.0  \n",
      "The cleaned table can be found at /Users/hetianlin/OneDrive/project_calc/data/curated/all_20201005.csv\n"
     ]
    }
   ],
   "source": [
    "x1=CLEAN1(f1+'Tianlin_GFR_CKD_EPI_31082020.xls')\n",
    "x1.remove_nan()\n",
    "x1.remove_s_creatinine_bySam()\n",
    "x1.remove_study()\n",
    "x1.remove_dialysis(f1+'checkedByGB_Tianlin_ntcvd.xlsx')\n",
    "x1.remove_age_below18()\n",
    "x1.remove_egfr_above(150)\n",
    "x1.egfr_predictionHBI()\n",
    "x1.merge_diseases(f1+'disease_group_SamHobson_PS_SH.xlsx')\n",
    "x1.exclude_diseases()\n",
    "x1.update_Calcification(f1+'Karltx_Matching_UrineSamples_Hannover_v4 (2).xlsx') # update diseases in study \"Calcification\"\n",
    "x1.insert_col_from_sql(f1+'acr_unit_date.xls','acr')\n",
    "x1.update_NTCVD(f1+'Tianlin_ntcvd_all_checkbyGB.xlsx')\n",
    "x1.replace_0_by_min('U_Albumin')\n",
    "x1.assign_sex()\n",
    "x1.albuminuria_group() #assign normal/micro/macro albuminuria\n",
    "x1.egfr_group(thres=[30,60,90],labels=[3,2,1,0]) #label 4 eGFR groups, larger the eGFR, smaller the label\n",
    "# to export all patients\n",
    "x1.export_csv(f2+'Tianlin_GFR_CKD_EPI_cleaned_20201005.csv')\n",
    "# to export train and test separately\n",
    "#x1.export_csv_train_test(f2+'train_20201005.csv',f2+'test_20201005.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}